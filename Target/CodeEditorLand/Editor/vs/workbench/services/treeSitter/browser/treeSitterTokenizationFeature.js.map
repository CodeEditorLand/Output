{
  "version": 3,
  "sources": ["../../../../../../../../../../Dependency/Land/Dependency/Editor/Source/vs/workbench/services/treeSitter/browser/treeSitterTokenizationFeature.ts"],
  "sourcesContent": ["/*---------------------------------------------------------------------------------------------\n *  Copyright (c) Microsoft Corporation. All rights reserved.\n *  Licensed under the MIT License. See License.txt in the project root for license information.\n *--------------------------------------------------------------------------------------------*/\n\nimport type { Parser } from '@vscode/tree-sitter-wasm';\nimport { Emitter, Event } from '../../../../base/common/event.js';\nimport { Disposable, DisposableMap, DisposableStore, IDisposable } from '../../../../base/common/lifecycle.js';\nimport { AppResourcePath, FileAccess } from '../../../../base/common/network.js';\nimport { ILanguageIdCodec, ITreeSitterTokenizationSupport, LazyTokenizationSupport, TreeSitterTokenizationRegistry } from '../../../../editor/common/languages.js';\nimport { ITextModel } from '../../../../editor/common/model.js';\nimport { EDITOR_EXPERIMENTAL_PREFER_TREESITTER, ITreeSitterParserService, ITreeSitterParseResult } from '../../../../editor/common/services/treeSitterParserService.js';\nimport { IModelTokensChangedEvent } from '../../../../editor/common/textModelEvents.js';\nimport { ColumnRange } from '../../../../editor/contrib/inlineCompletions/browser/utils.js';\nimport { IConfigurationService } from '../../../../platform/configuration/common/configuration.js';\nimport { IFileService } from '../../../../platform/files/common/files.js';\nimport { InstantiationType, registerSingleton } from '../../../../platform/instantiation/common/extensions.js';\nimport { createDecorator, IInstantiationService } from '../../../../platform/instantiation/common/instantiation.js';\nimport { IThemeService } from '../../../../platform/theme/common/themeService.js';\nimport { ColorThemeData, findMetadata } from '../../themes/common/colorThemeData.js';\nimport { ILanguageService } from '../../../../editor/common/languages/language.js';\n\nconst ALLOWED_SUPPORT = ['typescript'];\ntype TreeSitterQueries = string;\n\nexport const ITreeSitterTokenizationFeature = createDecorator<ITreeSitterTokenizationFeature>('treeSitterTokenizationFeature');\n\nexport interface ITreeSitterTokenizationFeature {\n\t_serviceBrand: undefined;\n}\n\nclass TreeSitterTokenizationFeature extends Disposable implements ITreeSitterTokenizationFeature {\n\tpublic _serviceBrand: undefined;\n\tprivate readonly _tokenizersRegistrations: DisposableMap<string, DisposableStore> = new DisposableMap();\n\n\tconstructor(\n\t\t@ILanguageService private readonly _languageService: ILanguageService,\n\t\t@IConfigurationService private readonly _configurationService: IConfigurationService,\n\t\t@IInstantiationService private readonly _instantiationService: IInstantiationService,\n\t\t@IFileService private readonly _fileService: IFileService\n\t) {\n\t\tsuper();\n\n\t\tthis._handleGrammarsExtPoint();\n\t\tthis._register(this._configurationService.onDidChangeConfiguration(e => {\n\t\t\tif (e.affectsConfiguration(EDITOR_EXPERIMENTAL_PREFER_TREESITTER)) {\n\t\t\t\tthis._handleGrammarsExtPoint();\n\t\t\t}\n\t\t}));\n\t}\n\n\tprivate _getSetting(): string[] {\n\t\treturn this._configurationService.getValue<string[]>(EDITOR_EXPERIMENTAL_PREFER_TREESITTER) || [];\n\t}\n\n\tprivate _handleGrammarsExtPoint(): void {\n\t\tconst setting = this._getSetting();\n\n\t\t// Eventually, this should actually use an extension point to add tree sitter grammars, but for now they are hard coded in core\n\t\tfor (const languageId of setting) {\n\t\t\tif (ALLOWED_SUPPORT.includes(languageId) && !this._tokenizersRegistrations.has(languageId)) {\n\t\t\t\tconst lazyTokenizationSupport = new LazyTokenizationSupport(() => this._createTokenizationSupport(languageId));\n\t\t\t\tconst disposableStore = new DisposableStore();\n\t\t\t\tdisposableStore.add(lazyTokenizationSupport);\n\t\t\t\tdisposableStore.add(TreeSitterTokenizationRegistry.registerFactory(languageId, lazyTokenizationSupport));\n\t\t\t\tthis._tokenizersRegistrations.set(languageId, disposableStore);\n\t\t\t\tTreeSitterTokenizationRegistry.getOrCreate(languageId);\n\t\t\t}\n\t\t}\n\t\tconst languagesToUnregister = [...this._tokenizersRegistrations.keys()].filter(languageId => !setting.includes(languageId));\n\t\tfor (const languageId of languagesToUnregister) {\n\t\t\tthis._tokenizersRegistrations.deleteAndDispose(languageId);\n\t\t}\n\t}\n\n\tprivate async _fetchQueries(newLanguage: string): Promise<TreeSitterQueries> {\n\t\tconst languageLocation: AppResourcePath = `vs/editor/common/languages/highlights/${newLanguage}.scm`;\n\t\tconst query = await this._fileService.readFile(FileAccess.asFileUri(languageLocation));\n\t\treturn query.value.toString();\n\t}\n\n\tprivate async _createTokenizationSupport(languageId: string): Promise<ITreeSitterTokenizationSupport & IDisposable | null> {\n\t\tconst queries = await this._fetchQueries(languageId);\n\t\treturn this._instantiationService.createInstance(TreeSitterTokenizationSupport, queries, languageId, this._languageService.languageIdCodec);\n\t}\n}\n\nclass TreeSitterTokenizationSupport extends Disposable implements ITreeSitterTokenizationSupport {\n\tprivate _query: Parser.Query | undefined;\n\tprivate readonly _onDidChangeTokens: Emitter<{ textModel: ITextModel; changes: IModelTokensChangedEvent }> = new Emitter();\n\tpublic readonly onDidChangeTokens: Event<{ textModel: ITextModel; changes: IModelTokensChangedEvent }> = this._onDidChangeTokens.event;\n\tprivate _colorThemeData!: ColorThemeData;\n\tprivate _languageAddedListener: IDisposable | undefined;\n\n\tconstructor(\n\t\tprivate readonly _queries: TreeSitterQueries,\n\t\tprivate readonly _languageId: string,\n\t\tprivate readonly _languageIdCodec: ILanguageIdCodec,\n\t\t@ITreeSitterParserService private readonly _treeSitterService: ITreeSitterParserService,\n\t\t@IThemeService private readonly _themeService: IThemeService,\n\t) {\n\t\tsuper();\n\t\tthis._register(Event.runAndSubscribe(this._themeService.onDidColorThemeChange, () => this.reset()));\n\t\tthis._register(this._treeSitterService.onDidUpdateTree((e) => {\n\t\t\tconst maxLine = e.textModel.getLineCount();\n\t\t\tthis._onDidChangeTokens.fire({\n\t\t\t\ttextModel: e.textModel,\n\t\t\t\tchanges: {\n\t\t\t\t\tsemanticTokensApplied: false,\n\t\t\t\t\tranges: e.ranges.map(range => ({ fromLineNumber: range.startLineNumber, toLineNumber: range.endLineNumber < maxLine ? range.endLineNumber : maxLine })),\n\t\t\t\t}\n\t\t\t});\n\t\t}));\n\t}\n\n\tprivate _getTree(textModel: ITextModel): ITreeSitterParseResult | undefined {\n\t\treturn this._treeSitterService.getParseResult(textModel);\n\t}\n\n\tprivate _ensureQuery() {\n\t\tif (!this._query) {\n\t\t\tconst language = this._treeSitterService.getOrInitLanguage(this._languageId);\n\t\t\tif (!language) {\n\t\t\t\tif (!this._languageAddedListener) {\n\t\t\t\t\tthis._languageAddedListener = this._register(Event.onceIf(this._treeSitterService.onDidAddLanguage, e => e.id === this._languageId)((e) => {\n\t\t\t\t\t\tthis._query = e.language.query(this._queries);\n\t\t\t\t\t}));\n\t\t\t\t}\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tthis._query = language.query(this._queries);\n\t\t}\n\t\treturn this._query;\n\t}\n\n\tprivate reset() {\n\t\tthis._colorThemeData = this._themeService.getColorTheme() as ColorThemeData;\n\t}\n\n\tcaptureAtPosition(lineNumber: number, column: number, textModel: ITextModel): Parser.QueryCapture[] {\n\t\tconst tree = this._getTree(textModel);\n\t\tconst captures = this._captureAtRange(lineNumber, new ColumnRange(column, column), tree?.tree);\n\t\treturn captures;\n\t}\n\n\tcaptureAtPositionTree(lineNumber: number, column: number, tree: Parser.Tree): Parser.QueryCapture[] {\n\t\tconst captures = this._captureAtRange(lineNumber, new ColumnRange(column, column), tree);\n\t\treturn captures;\n\t}\n\n\n\tprivate _captureAtRange(lineNumber: number, columnRange: ColumnRange, tree: Parser.Tree | undefined): Parser.QueryCapture[] {\n\t\tconst query = this._ensureQuery();\n\t\tif (!tree || !query) {\n\t\t\treturn [];\n\t\t}\n\t\t// Tree sitter row is 0 based, column is 0 based\n\t\treturn query.captures(tree.rootNode, { startPosition: { row: lineNumber - 1, column: columnRange.startColumn - 1 }, endPosition: { row: lineNumber - 1, column: columnRange.endColumnExclusive } });\n\t}\n\n\t/**\n\t * Gets the tokens for a given line.\n\t * Each token takes 2 elements in the array. The first element is the offset of the end of the token *in the line, not in the document*, and the second element is the metadata.\n\t *\n\t * @param lineNumber\n\t * @returns\n\t */\n\tpublic tokenizeEncoded(lineNumber: number, textModel: ITextModel): Uint32Array | undefined {\n\t\tconst lineLength = textModel.getLineMaxColumn(lineNumber);\n\t\tconst tree = this._getTree(textModel);\n\t\tconst captures = this._captureAtRange(lineNumber, new ColumnRange(1, lineLength), tree?.tree);\n\n\t\tif (captures.length === 0) {\n\t\t\treturn undefined;\n\t\t}\n\n\t\tconst endOffsetsAndScopes: { endOffset: number; scopes: string[] }[] = Array(captures.length);\n\t\tendOffsetsAndScopes.fill({ endOffset: 0, scopes: [] });\n\t\tlet tokenIndex = 0;\n\t\tconst lineStartOffset = textModel.getOffsetAt({ lineNumber: lineNumber, column: 1 });\n\n\t\tconst increaseSizeOfTokensByOneToken = () => {\n\t\t\tendOffsetsAndScopes.push({ endOffset: 0, scopes: [] });\n\t\t};\n\n\t\tconst encodedLanguageId = this._languageIdCodec.encodeLanguageId(this._languageId);\n\n\t\tfor (let captureIndex = 0; captureIndex < captures.length; captureIndex++) {\n\t\t\tconst capture = captures[captureIndex];\n\t\t\tconst tokenEndIndex = capture.node.endIndex < lineStartOffset + lineLength ? capture.node.endIndex : lineStartOffset + lineLength;\n\t\t\tconst tokenStartIndex = capture.node.startIndex < lineStartOffset ? lineStartOffset : capture.node.startIndex;\n\n\t\t\tconst lineRelativeOffset = tokenEndIndex - lineStartOffset;\n\t\t\t// Not every character will get captured, so we need to make sure that our current capture doesn't bleed toward the start of the line and cover characters that it doesn't apply to.\n\t\t\t// We do this by creating a new token in the array if the previous token ends before the current token starts.\n\t\t\tlet previousTokenEnd: number;\n\t\t\tconst currentTokenLength = tokenEndIndex - tokenStartIndex;\n\t\t\tif (captureIndex > 0) {\n\t\t\t\tpreviousTokenEnd = endOffsetsAndScopes[(tokenIndex - 1)].endOffset;\n\t\t\t} else {\n\t\t\t\tpreviousTokenEnd = tokenStartIndex - lineStartOffset - 1;\n\t\t\t}\n\t\t\tconst intermediateTokenOffset = lineRelativeOffset - currentTokenLength;\n\t\t\tif ((previousTokenEnd >= 0) && (previousTokenEnd < intermediateTokenOffset)) {\n\t\t\t\t// Add en empty token to cover the space where there were no captures\n\t\t\t\tendOffsetsAndScopes[tokenIndex] = { endOffset: intermediateTokenOffset, scopes: [] };\n\t\t\t\ttokenIndex++;\n\n\t\t\t\tincreaseSizeOfTokensByOneToken();\n\t\t\t}\n\n\t\t\tconst addCurrentTokenToArray = () => {\n\t\t\t\tendOffsetsAndScopes[tokenIndex] = { endOffset: lineRelativeOffset, scopes: [capture.name] };\n\t\t\t\ttokenIndex++;\n\t\t\t};\n\n\t\t\tif (previousTokenEnd >= lineRelativeOffset) {\n\t\t\t\tconst previousTokenStartOffset = ((tokenIndex >= 2) ? endOffsetsAndScopes[tokenIndex - 2].endOffset : 0);\n\t\t\t\tconst originalPreviousTokenEndOffset = endOffsetsAndScopes[tokenIndex - 1].endOffset;\n\n\t\t\t\t// Check that the current token doesn't just replace the last token\n\t\t\t\tif ((previousTokenStartOffset + currentTokenLength) === originalPreviousTokenEndOffset) {\n\t\t\t\t\t// Current token and previous token span the exact same characters, replace the last scope\n\t\t\t\t\tendOffsetsAndScopes[tokenIndex - 1].scopes[endOffsetsAndScopes[tokenIndex - 1].scopes.length - 1] = capture.name;\n\t\t\t\t} else {\n\t\t\t\t\t// The current token is within the previous token. Adjust the end of the previous token.\n\t\t\t\t\tendOffsetsAndScopes[tokenIndex - 1].endOffset = intermediateTokenOffset;\n\n\t\t\t\t\taddCurrentTokenToArray();\n\t\t\t\t\t// Add the rest of the previous token after the current token\n\t\t\t\t\tincreaseSizeOfTokensByOneToken();\n\t\t\t\t\tendOffsetsAndScopes[tokenIndex].endOffset = originalPreviousTokenEndOffset;\n\t\t\t\t\tendOffsetsAndScopes[tokenIndex].scopes = endOffsetsAndScopes[tokenIndex - 2].scopes;\n\t\t\t\t\ttokenIndex++;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// Just add the token to the array\n\t\t\t\taddCurrentTokenToArray();\n\t\t\t}\n\t\t}\n\n\t\t// Account for uncaptured characters at the end of the line\n\t\tif (captures[captures.length - 1].node.endPosition.column + 1 < lineLength) {\n\t\t\tincreaseSizeOfTokensByOneToken();\n\t\t\tendOffsetsAndScopes[tokenIndex].endOffset = lineLength - 1;\n\t\t\ttokenIndex++;\n\t\t}\n\n\t\tconst tokens: Uint32Array = new Uint32Array((tokenIndex) * 2);\n\t\tfor (let i = 0; i < tokenIndex; i++) {\n\t\t\tconst token = endOffsetsAndScopes[i];\n\t\t\tif (token.endOffset === 0 && token.scopes.length === 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttokens[i * 2] = token.endOffset;\n\t\t\ttokens[i * 2 + 1] = findMetadata(this._colorThemeData, token.scopes, encodedLanguageId);\n\t\t}\n\n\t\treturn tokens;\n\t}\n\n\toverride dispose() {\n\t\tsuper.dispose();\n\t\tthis._query?.delete();\n\t\tthis._query = undefined;\n\t}\n}\n\nregisterSingleton(ITreeSitterTokenizationFeature, TreeSitterTokenizationFeature, InstantiationType.Eager);\n\n"],
  "mappings": ";;;;;;;;;;;;AAMA,SAAS,SAAS,aAAa;AAC/B,SAAS,YAAY,eAAe,iBAAiB,mBAAmB;AACxE,SAAS,iBAAiB,kBAAkB;AAC5C,SAAS,kBAAkB,gCAAgC,yBAAyB,sCAAsC;AAC1H,SAAS,kBAAkB;AAC3B,SAAS,uCAAuC,0BAA0B,8BAA8B;AACxG,SAAS,gCAAgC;AACzC,SAAS,mBAAmB;AAC5B,SAAS,6BAA6B;AACtC,SAAS,oBAAoB;AAC7B,SAAS,mBAAmB,yBAAyB;AACrD,SAAS,iBAAiB,6BAA6B;AACvD,SAAS,qBAAqB;AAC9B,SAAS,gBAAgB,oBAAoB;AAC7C,SAAS,wBAAwB;AAEjC,MAAM,kBAAkB,CAAC,YAAY;AAG9B,MAAM,iCAAiC,gBAAgD,+BAA+B;AAM7H,IAAM,gCAAN,cAA4C,WAAqD;AAAA,EAIhG,YACoC,kBACK,uBACA,uBACT,cAC9B;AACD,UAAM;AAL6B;AACK;AACA;AACT;AAI/B,SAAK,wBAAwB;AAC7B,SAAK,UAAU,KAAK,sBAAsB,yBAAyB,OAAK;AACvE,UAAI,EAAE,qBAAqB,qCAAqC,GAAG;AAClE,aAAK,wBAAwB;AAAA,MAC9B;AAAA,IACD,CAAC,CAAC;AAAA,EACH;AAAA,EAjDD,OA+BiG;AAAA;AAAA;AAAA,EACzF;AAAA,EACU,2BAAmE,IAAI,cAAc;AAAA,EAkB9F,cAAwB;AAC/B,WAAO,KAAK,sBAAsB,SAAmB,qCAAqC,KAAK,CAAC;AAAA,EACjG;AAAA,EAEQ,0BAAgC;AACvC,UAAM,UAAU,KAAK,YAAY;AAGjC,eAAW,cAAc,SAAS;AACjC,UAAI,gBAAgB,SAAS,UAAU,KAAK,CAAC,KAAK,yBAAyB,IAAI,UAAU,GAAG;AAC3F,cAAM,0BAA0B,IAAI,wBAAwB,MAAM,KAAK,2BAA2B,UAAU,CAAC;AAC7G,cAAM,kBAAkB,IAAI,gBAAgB;AAC5C,wBAAgB,IAAI,uBAAuB;AAC3C,wBAAgB,IAAI,+BAA+B,gBAAgB,YAAY,uBAAuB,CAAC;AACvG,aAAK,yBAAyB,IAAI,YAAY,eAAe;AAC7D,uCAA+B,YAAY,UAAU;AAAA,MACtD;AAAA,IACD;AACA,UAAM,wBAAwB,CAAC,GAAG,KAAK,yBAAyB,KAAK,CAAC,EAAE,OAAO,gBAAc,CAAC,QAAQ,SAAS,UAAU,CAAC;AAC1H,eAAW,cAAc,uBAAuB;AAC/C,WAAK,yBAAyB,iBAAiB,UAAU;AAAA,IAC1D;AAAA,EACD;AAAA,EAEA,MAAc,cAAc,aAAiD;AAC5E,UAAM,mBAAoC,yCAAyC,WAAW;AAC9F,UAAM,QAAQ,MAAM,KAAK,aAAa,SAAS,WAAW,UAAU,gBAAgB,CAAC;AACrF,WAAO,MAAM,MAAM,SAAS;AAAA,EAC7B;AAAA,EAEA,MAAc,2BAA2B,YAAkF;AAC1H,UAAM,UAAU,MAAM,KAAK,cAAc,UAAU;AACnD,WAAO,KAAK,sBAAsB,eAAe,+BAA+B,SAAS,YAAY,KAAK,iBAAiB,eAAe;AAAA,EAC3I;AACD;AAtDM,gCAAN;AAAA,EAKG;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,GARG;AAwDN,IAAM,gCAAN,cAA4C,WAAqD;AAAA,EAOhG,YACkB,UACA,aACA,kBAC0B,oBACX,eAC/B;AACD,UAAM;AANW;AACA;AACA;AAC0B;AACX;AAGhC,SAAK,UAAU,MAAM,gBAAgB,KAAK,cAAc,uBAAuB,MAAM,KAAK,MAAM,CAAC,CAAC;AAClG,SAAK,UAAU,KAAK,mBAAmB,gBAAgB,CAAC,MAAM;AAC7D,YAAM,UAAU,EAAE,UAAU,aAAa;AACzC,WAAK,mBAAmB,KAAK;AAAA,QAC5B,WAAW,EAAE;AAAA,QACb,SAAS;AAAA,UACR,uBAAuB;AAAA,UACvB,QAAQ,EAAE,OAAO,IAAI,YAAU,EAAE,gBAAgB,MAAM,iBAAiB,cAAc,MAAM,gBAAgB,UAAU,MAAM,gBAAgB,QAAQ,EAAE;AAAA,QACvJ;AAAA,MACD,CAAC;AAAA,IACF,CAAC,CAAC;AAAA,EACH;AAAA,EAjHD,OAuFiG;AAAA;AAAA;AAAA,EACxF;AAAA,EACS,qBAA4F,IAAI,QAAQ;AAAA,EACzG,oBAAyF,KAAK,mBAAmB;AAAA,EACzH;AAAA,EACA;AAAA,EAuBA,SAAS,WAA2D;AAC3E,WAAO,KAAK,mBAAmB,eAAe,SAAS;AAAA,EACxD;AAAA,EAEQ,eAAe;AACtB,QAAI,CAAC,KAAK,QAAQ;AACjB,YAAM,WAAW,KAAK,mBAAmB,kBAAkB,KAAK,WAAW;AAC3E,UAAI,CAAC,UAAU;AACd,YAAI,CAAC,KAAK,wBAAwB;AACjC,eAAK,yBAAyB,KAAK,UAAU,MAAM,OAAO,KAAK,mBAAmB,kBAAkB,OAAK,EAAE,OAAO,KAAK,WAAW,EAAE,CAAC,MAAM;AAC1I,iBAAK,SAAS,EAAE,SAAS,MAAM,KAAK,QAAQ;AAAA,UAC7C,CAAC,CAAC;AAAA,QACH;AACA;AAAA,MACD;AACA,WAAK,SAAS,SAAS,MAAM,KAAK,QAAQ;AAAA,IAC3C;AACA,WAAO,KAAK;AAAA,EACb;AAAA,EAEQ,QAAQ;AACf,SAAK,kBAAkB,KAAK,cAAc,cAAc;AAAA,EACzD;AAAA,EAEA,kBAAkB,YAAoB,QAAgB,WAA8C;AACnG,UAAM,OAAO,KAAK,SAAS,SAAS;AACpC,UAAM,WAAW,KAAK,gBAAgB,YAAY,IAAI,YAAY,QAAQ,MAAM,GAAG,MAAM,IAAI;AAC7F,WAAO;AAAA,EACR;AAAA,EAEA,sBAAsB,YAAoB,QAAgB,MAA0C;AACnG,UAAM,WAAW,KAAK,gBAAgB,YAAY,IAAI,YAAY,QAAQ,MAAM,GAAG,IAAI;AACvF,WAAO;AAAA,EACR;AAAA,EAGQ,gBAAgB,YAAoB,aAA0B,MAAsD;AAC3H,UAAM,QAAQ,KAAK,aAAa;AAChC,QAAI,CAAC,QAAQ,CAAC,OAAO;AACpB,aAAO,CAAC;AAAA,IACT;AAEA,WAAO,MAAM,SAAS,KAAK,UAAU,EAAE,eAAe,EAAE,KAAK,aAAa,GAAG,QAAQ,YAAY,cAAc,EAAE,GAAG,aAAa,EAAE,KAAK,aAAa,GAAG,QAAQ,YAAY,mBAAmB,EAAE,CAAC;AAAA,EACnM;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EASO,gBAAgB,YAAoB,WAAgD;AAC1F,UAAM,aAAa,UAAU,iBAAiB,UAAU;AACxD,UAAM,OAAO,KAAK,SAAS,SAAS;AACpC,UAAM,WAAW,KAAK,gBAAgB,YAAY,IAAI,YAAY,GAAG,UAAU,GAAG,MAAM,IAAI;AAE5F,QAAI,SAAS,WAAW,GAAG;AAC1B,aAAO;AAAA,IACR;AAEA,UAAM,sBAAiE,MAAM,SAAS,MAAM;AAC5F,wBAAoB,KAAK,EAAE,WAAW,GAAG,QAAQ,CAAC,EAAE,CAAC;AACrD,QAAI,aAAa;AACjB,UAAM,kBAAkB,UAAU,YAAY,EAAE,YAAwB,QAAQ,EAAE,CAAC;AAEnF,UAAM,iCAAiC,6BAAM;AAC5C,0BAAoB,KAAK,EAAE,WAAW,GAAG,QAAQ,CAAC,EAAE,CAAC;AAAA,IACtD,GAFuC;AAIvC,UAAM,oBAAoB,KAAK,iBAAiB,iBAAiB,KAAK,WAAW;AAEjF,aAAS,eAAe,GAAG,eAAe,SAAS,QAAQ,gBAAgB;AAC1E,YAAM,UAAU,SAAS,YAAY;AACrC,YAAM,gBAAgB,QAAQ,KAAK,WAAW,kBAAkB,aAAa,QAAQ,KAAK,WAAW,kBAAkB;AACvH,YAAM,kBAAkB,QAAQ,KAAK,aAAa,kBAAkB,kBAAkB,QAAQ,KAAK;AAEnG,YAAM,qBAAqB,gBAAgB;AAG3C,UAAI;AACJ,YAAM,qBAAqB,gBAAgB;AAC3C,UAAI,eAAe,GAAG;AACrB,2BAAmB,oBAAqB,aAAa,CAAE,EAAE;AAAA,MAC1D,OAAO;AACN,2BAAmB,kBAAkB,kBAAkB;AAAA,MACxD;AACA,YAAM,0BAA0B,qBAAqB;AACrD,UAAK,oBAAoB,KAAO,mBAAmB,yBAA0B;AAE5E,4BAAoB,UAAU,IAAI,EAAE,WAAW,yBAAyB,QAAQ,CAAC,EAAE;AACnF;AAEA,uCAA+B;AAAA,MAChC;AAEA,YAAM,yBAAyB,6BAAM;AACpC,4BAAoB,UAAU,IAAI,EAAE,WAAW,oBAAoB,QAAQ,CAAC,QAAQ,IAAI,EAAE;AAC1F;AAAA,MACD,GAH+B;AAK/B,UAAI,oBAAoB,oBAAoB;AAC3C,cAAM,2BAA6B,cAAc,IAAK,oBAAoB,aAAa,CAAC,EAAE,YAAY;AACtG,cAAM,iCAAiC,oBAAoB,aAAa,CAAC,EAAE;AAG3E,YAAK,2BAA2B,uBAAwB,gCAAgC;AAEvF,8BAAoB,aAAa,CAAC,EAAE,OAAO,oBAAoB,aAAa,CAAC,EAAE,OAAO,SAAS,CAAC,IAAI,QAAQ;AAAA,QAC7G,OAAO;AAEN,8BAAoB,aAAa,CAAC,EAAE,YAAY;AAEhD,iCAAuB;AAEvB,yCAA+B;AAC/B,8BAAoB,UAAU,EAAE,YAAY;AAC5C,8BAAoB,UAAU,EAAE,SAAS,oBAAoB,aAAa,CAAC,EAAE;AAC7E;AAAA,QACD;AAAA,MACD,OAAO;AAEN,+BAAuB;AAAA,MACxB;AAAA,IACD;AAGA,QAAI,SAAS,SAAS,SAAS,CAAC,EAAE,KAAK,YAAY,SAAS,IAAI,YAAY;AAC3E,qCAA+B;AAC/B,0BAAoB,UAAU,EAAE,YAAY,aAAa;AACzD;AAAA,IACD;AAEA,UAAM,SAAsB,IAAI,YAAa,aAAc,CAAC;AAC5D,aAAS,IAAI,GAAG,IAAI,YAAY,KAAK;AACpC,YAAM,QAAQ,oBAAoB,CAAC;AACnC,UAAI,MAAM,cAAc,KAAK,MAAM,OAAO,WAAW,GAAG;AACvD;AAAA,MACD;AACA,aAAO,IAAI,CAAC,IAAI,MAAM;AACtB,aAAO,IAAI,IAAI,CAAC,IAAI,aAAa,KAAK,iBAAiB,MAAM,QAAQ,iBAAiB;AAAA,IACvF;AAEA,WAAO;AAAA,EACR;AAAA,EAES,UAAU;AAClB,UAAM,QAAQ;AACd,SAAK,QAAQ,OAAO;AACpB,SAAK,SAAS;AAAA,EACf;AACD;AAnLM,gCAAN;AAAA,EAWG;AAAA,EACA;AAAA,GAZG;AAqLN,kBAAkB,gCAAgC,+BAA+B,kBAAkB,KAAK;",
  "names": []
}
